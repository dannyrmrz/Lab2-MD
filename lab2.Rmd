---
title: "Lab2"
author: "Daniela Ramírez, Adrián Gonzáles y José Ordoñez"
date: "2026-02-23"
output: pdf_document
---

```{r librerias}
library(tidyverse)
library(lubridate)
library(cluster)
library(factoextra)
library(hopkins)
library(NbClust)
library(psych)
library(FactoMineR)
library(fpc)
library(factoextra)
library(corrplot)
library(PCAmixdata)
library(paran)
library(arules)
library(arulesViz)
```


```{r datos}
movies <- read.csv("movies_2026.csv", stringsAsFactors = F)

str(movies)
```

```{r}
#Preprocesamiento de datos

movies_clust <- movies %>%
  dplyr::select(-id,
         -originalTitle,
         -title,
         -homePage,
         -director,
         -actors,
         -actorsCharacter,
         -productionCompany,
         -productionCompanyCountry,
         -productionCountry,
         -releaseDate)

# Eliminar NA
movies_clust <- movies_clust %>%
  drop_na()

# Seleccionar variables numéricas
movies_num <- movies_clust %>%
  dplyr::select(where(is.numeric))

# Escalar datos
movies_scaled <- scale(movies_num)
```

```{r}

set.seed(123)

# Tomar muestra de 1000 observaciones
sample_index <- sample(1:nrow(movies_scaled), 1000)

movies_sample <- movies_scaled[sample_index, ]

# Hopkins
hopkins_stat <- hopkins::hopkins(
  X = movies_sample,
  m = floor(0.1 * nrow(movies_sample))
)

hopkins_stat
```
El estadístico de Hopkins obtuvo un valor de 0.999999999997353.

Un valor cercano a 1 indica fuerte tendencia al agrupamiento, mientras que valores cercanos a 0.5 indican distribución aleatoria.

Dado que el valor obtenido es mayor a 0.9, existe evidencia de que los datos presentan estructura de agrupamiento y por lo tanto es adecuado aplicar algoritmos de clustering.


```{r} 
# VAT con muestra
dist_matrix_sample <- dist(movies_sample)

image(as.matrix(dist_matrix_sample),
      main = "VAT - Visual Assessment (Muestra)")

fviz_dist(dist_matrix_sample,
          show_labels = FALSE) +
  ggtitle("Visual Assessment of Cluster Tendency (Muestra)")
```
La evaluación visual de la matriz de distancias muestra variaciones en la intensidad del color, lo cual sugiere cierta estructura en los datos. No se observan bloques completamente definidos, lo que indica que los grupos no están perfectamente separados, pero sí existe tendencia al agrupamiento.
Este resultado es consistente con el estadístico de Hopkins obtenido previamente, el cual confirmó la presencia de estructura no aleatoria en los datos.


```{r}
#Codo

fviz_nbclust(movies_scaled, kmeans, method = "wss") +
  ggtitle("Método del Codo")

# Ajustar según gráfica
k_opt <- 3
```
En la gráfica del método del codo se observa un punto de inflexión claro en k = 3, a partir del cual la reducción en la suma de cuadrados intra-cluster comienza a disminuir de forma más gradual.
Por esta razón se selecciona k = 3 como número óptimo de clusters, ya que representa un equilibrio adecuado entre reducción de variabilidad interna y simplicidad del modelo.


```{r}
#k-means

set.seed(123)

kmeans_model <- kmeans(
  movies_scaled,
  centers = k_opt,
  nstart = 25
)

movies_clust$kmeans_cluster <- kmeans_model$cluster
```

```{r}
#Clustering jerárquico

dist_matrix <- dist(movies_scaled)

hc_model <- hclust(dist_matrix, method = "ward.D2")

plot(hc_model, labels = FALSE)

hc_clusters <- cutree(hc_model, k = k_opt)

movies_clust$hc_cluster <- hc_clusters
```

```{r}
#Silueta

# K-means
sil_kmeans <- silhouette(kmeans_model$cluster, dist_matrix)

fviz_silhouette(sil_kmeans)

mean(sil_kmeans[, 3])


# Jerárquico
sil_hc <- silhouette(hc_clusters, dist_matrix)

fviz_silhouette(sil_hc)

mean(sil_hc[, 3])
```
El promedio del índice de silueta para K-means fue 0.357, mientras que para el clustering jerárquico fue 0.330.

Aunque ambos métodos presentan una separación moderada entre grupos, K-means muestra un mejor desempeño global según el promedio de silueta.

Por esta razón se selecciona K-means como el método definitivo para la interpretación de los clusters.

```{r}
#Interpretación de datos
movies_clust %>%
  group_by(kmeans_cluster) %>%
  summarise(across(where(is.numeric), mean))

# Géneros
movies_clust %>%
  group_by(kmeans_cluster, genres) %>%
  summarise(n = n()) %>%
  arrange(kmeans_cluster, desc(n))

# Idioma original
movies_clust %>%
  group_by(kmeans_cluster, originalLanguage) %>%
  summarise(n = n()) %>%
  arrange(kmeans_cluster, desc(n))
```

## Interpretación de los Clusters (K-means)

Cluster 1:
Se caracteriza por películas de alto presupuesto (≈88 millones) y altos ingresos (≈327 millones), con elevada popularidad y duración promedio de 121 minutos. Predominan producciones en idioma inglés y géneros comerciales como comedia, drama y acción/aventura. Este grupo representa películas comerciales de alto rendimiento o “blockbusters” orientadas al mercado internacional.

Cluster 2:
Incluye películas de presupuesto medio (≈9 millones) y recaudación moderada (≈20 millones). Presentan menor popularidad en comparación con el Cluster 1 y mayor diversidad de idiomas, incluyendo producciones en inglés y japonés. Este grupo puede interpretarse como cine independiente o producciones regionales con alcance moderado.

Cluster 3:
Está compuesto por producciones de muy bajo presupuesto y escasa recaudación, con baja duración promedio y mínima popularidad. Este segmento podría representar cortometrajes o producciones de bajo impacto comercial.



```{r datos-pca}
datos_pca <- movies[, c(
  "budget",
  "revenue",
  "runtime",
  "popularity",
  "voteAvg",
  "voteCount",
  "genresAmount",
  "productionCoAmount",
  "productionCountriesAmount",
  "actorsAmount",
  "castWomenAmount",
  "castMenAmount"
)]
```

## Inclusión de variables categóricas en el PCA

Las variables categóricas como género, idioma original o país de producción podrían transformarse mediante técnicas como codificación one-hot (dummies) para ser incluidas en el análisis.

Sin embargo, este tipo de transformación incrementaría considerablemente la dimensionalidad del conjunto de datos y podría introducir alta dispersión y ruido, afectando la estabilidad de los componentes principales.

Dado que el objetivo del PCA es reducir dimensionalidad y sintetizar información relevante, se decidió utilizar únicamente variables numéricas, ya que estas representan directamente magnitudes financieras, de popularidad y estructura de producción.

Por lo tanto, no se consideró conveniente incluir variables categóricas transformadas en este análisis.

```{r aplicar-pca}
rcor<-cor(datos_pca, use = "complete.obs")
det(rcor)

KMO(as.matrix(datos_pca))

```
Al obtener la determinante de la matriz de correlación, nos indica que las variables si están relacionadas entre si.

Utilizamos KMO para determinar si se puede utilizar análisis factorial para las combinaciones lineales de las variables.
Obtuvimos 0.76 como indice, esto se encuentra entre 0.7 y 0.8, lo cual nos indica que es una adecuación muestral aceptable.

```{r matriz-correlación}
matriz <- cor(datos_pca[,-1],use = "pairwise.complete.obs")
corrplot(matriz)
```
La matriz de correlación muestra múltiples correlaciones positivas moderadas y fuertes entre variables como revenue, voteCount y voteAvg, así como entre las variables relacionadas con el reparto y la producción. Esto indica redundancia de información y presencia de multicolinealidad, lo cual respalda la aplicación del Análisis de Componentes Principales para sintetizar la información en un menor número de componentes.

# Prueba de Esfericidad de Bartlett

``` {r}
cortest.bartlett(matriz, n = nrow(datos_pca))
```

La prueba de Bartlett arrojó un estadístico χ² = 50302.23 con 55 grados de libertad y un p-value < 0.001.
Dado que el valor p es menor a 0.05, se rechaza la hipótesis nula de que la matriz de correlación sea identidad.

Esto indica que existe correlación significativa entre las variables y, por lo tanto, es apropiado aplicar el Análisis de Componentes Principales.

# Índice KMO

``` {r}
KMO(matriz)
```
El índice KMO global fue 0.70, lo cual indica una adecuación aceptable del modelo factorial.

Aunque algunas variables presentan valores individuales bajos (principalmente las relacionadas con el elenco), el valor global sugiere que el conjunto de datos es adecuado para aplicar PCA.

# Ajustes adicionales
```{r}
# Convertir a numérico
datos_pca[] <- lapply(datos_pca, function(x) as.numeric(as.character(x)))

# Eliminar NA
datos_pca <- na.omit(datos_pca)

# Escalar datos
datos_scaled <- scale(datos_pca)

# Crear objeto PCA
pca <- prcomp(datos_scaled, center = TRUE, scale. = TRUE)
```


```{r}
summary(pca)
fviz_eig(pca, addlabels = TRUE)
round(pca$rotation, 3)
```

El análisis muestra que:

La primera componente explica 38.23% de la varianza.

Las primeras cuatro componentes explican aproximadamente 71% de la variabilidad total.

Por lo tanto, se seleccionan 4 componentes principales, ya que permiten reducir la dimensionalidad manteniendo la mayor parte de la información del conjunto de datos.

Las cargas factoriales indican que:

### Componente Principal 1 (PC1)

PC1 presenta cargas altas y positivas en variables como budget, revenue, voteCount y actorsAmount.

Esto indica que esta componente representa una dimensión asociada al impacto comercial y escala de producción.

### Componente Principal 2 (PC2)

PC2 muestra asociación con variables como productionCountriesAmount y productionCoAmount, lo que sugiere una dimensión relacionada con la complejidad e internacionalización de la producción.

Esta componente podría interpretarse como una medida del grado de colaboración internacional en la película.

### Componente Principal 3 (PC3)

PC3 se relaciona principalmente con variables del elenco (actorsAmount, castWomenAmount, castMenAmount), representando la estructura del reparto y composición del cast.

Esta dimensión permite diferenciar producciones según tamaño y composición del elenco.

### Componente Principal 4 (PC4)

PC4 está fuertemente influenciada por la variable popularity, representando una dimensión más asociada a percepción pública y tendencia mediática que a magnitudes financieras directas.

PCA es una técnica adecuada para sintetizar la información del dataset.


## 2. Reglas de Asociación
```{r}
# Preparación para reglas de asociación

#La que se usó antes de saber si valía la pena eliminar variables frecuentes

movies_rules <- movies %>%
  dplyr::select(
    genres,
    originalLanguage,
    productionCountry,
    budget,
    revenue,
    popularity,
    runtime,
    voteAvg,
    actorsAmount
  ) %>%
  filter(budget > 0,
         revenue > 0) %>%
  drop_na()
```
Se eliminaron películas con presupuesto y recaudación igual a cero, ya que representaban valores faltantes o producciones sin información financiera válida, lo que afectaba la discretización y generación de reglas.

```{r}
movies_rules_refined <- movies_rules %>%
  dplyr::select(-originalLanguage, -productionCountry)

movies_trans_refined <- as(movies_rules_refined, "transactions")

rules_refined <- apriori(
  movies_trans_refined,
  parameter = list(
    supp = 0.03,
    conf = 0.8,
    minlen = 2
  )
)

summary(rules_refined)
inspect(head(sort(rules_refined, by = "lift"), 10))
```

```{r}
movies_rules$budget <- as.numeric(movies_rules$budget)
movies_rules$revenue <- as.numeric(movies_rules$revenue)
movies_rules$popularity <- as.numeric(movies_rules$popularity)
movies_rules$runtime <- as.numeric(movies_rules$runtime)
movies_rules$voteAvg <- as.numeric(movies_rules$voteAvg)
movies_rules$actorsAmount <- as.numeric(movies_rules$actorsAmount)
```

```{r}
# Discretización

movies_rules$budget <- arules::discretize(movies_rules$budget, method = "interval", breaks = 3)
movies_rules$revenue <- arules::discretize(movies_rules$revenue, method = "interval", breaks = 3)
movies_rules$popularity <- arules::discretize(movies_rules$popularity, method = "interval", breaks = 3)
movies_rules$runtime <- arules::discretize(movies_rules$runtime, method = "interval", breaks = 3)
movies_rules$voteAvg <- arules::discretize(movies_rules$voteAvg, method = "interval", breaks = 3)
movies_rules$actorsAmount <- arules::discretize(movies_rules$actorsAmount, method = "interval", breaks = 3)
```
Se utilizó discretización por intervalos iguales con tres categorías (bajo, medio y alto), lo que permitió dividir las variables numéricas en rangos homogéneos y evitar problemas derivados de distribuciones altamente concentradas.

```{r}
# Transacciones

movies_trans <- as(movies_rules, "transactions")

summary(movies_trans)
```

```{r}
# A priori - Prueba 1

rules1 <- apriori(
  movies_trans,
  parameter = list(
    supp = 0.05,
    conf = 0.7,
    minlen = 2
  )
)

summary(rules1)

inspect(head(sort(rules1, by = "lift"), 10))
```
Se generaron 564 reglas utilizando el algoritmo A priori con soporte mínimo de 0.05 y confianza mínima de 0.7.

El soporte promedio fue 0.09, mientras que la confianza promedio alcanzó 0.89, lo cual indica que las reglas encontradas presentan alta probabilidad condicional. El valor máximo de lift fue 2.83, lo que sugiere asociaciones que ocurren casi tres veces más frecuentemente de lo esperado bajo independencia.

Las reglas más relevantes muestran que películas con alto presupuesto, elevada popularidad, mayor duración y un elenco numeroso tienden a generar altos ingresos. En particular, las reglas con mayor lift relacionan directamente variables financieras (budget y revenue) con variables de percepción pública (popularity y voteAvg).

Por ejemplo, se observó que películas con presupuesto alto y alta popularidad presentan más del 90% de probabilidad de ubicarse en la categoría de ingresos altos, con un lift superior a 2.7, lo que indica una fuerte asociación.

Asimismo, se identificó que variables como idioma inglés y producción en Estados Unidos aparecen con alta frecuencia, lo que genera reglas menos informativas debido a su dominancia en el dataset. Sin embargo, al analizar las reglas con mayor lift, se evidencia que los factores financieros y de popularidad son los principales determinantes del rendimiento económico.

## ¿Conviene eliminar idioma y país?
Aunque inicialmente se mantuvieron estas variables para evaluar su impacto en las reglas generadas, el análisis de frecuencia mostró que dominaban el conjunto de datos. Por esta razón, se decidió eliminarlas y volver a ejecutar el algoritmo A priori con el fin de obtener asociaciones más informativas.

```{r}
# A priori - Prueba 2

rules2 <- apriori(
  movies_trans,
  parameter = list(
    supp = 0.03,
    conf = 0.8,
    minlen = 2
  )
)

summary(rules2)

inspect(head(sort(rules2, by = "lift"), 10))
```
##Comparación entre configuraciones de soporte y confianza

Se realizaron dos configuraciones del algoritmo A priori:

Configuración 1: soporte = 0.05, confianza = 0.7 (564 reglas)
Configuración 2: soporte = 0.03, confianza = 0.8 (809 reglas)

Al reducir el soporte mínimo se generaron más reglas, ya que se permitieron asociaciones menos frecuentes. Asimismo, al aumentar la confianza mínima se obtuvieron reglas con mayor probabilidad condicional.

La segunda configuración produjo reglas con confianza promedio de 0.94 y lift máximo de 2.91, superiores a los valores obtenidos en la primera configuración. Esto indica asociaciones más fuertes, aunque ligeramente menos frecuentes.

En ambas configuraciones se identificó un patrón consistente: películas con alto presupuesto, alta popularidad, mayor calificación promedio y un elenco amplio presentan alta probabilidad de generar ingresos elevados. Estas asociaciones presentan niveles de confianza superiores al 90% y lift cercanos a 3, lo que indica una relación significativamente mayor a la esperada bajo independencia.

Aunque variables como idioma inglés y producción en Estados Unidos aparecen con alta frecuencia, el análisis muestra que las variables financieras y de popularidad son los principales determinantes del éxito comercial.

Se considera que la segunda configuración (supp = 0.03, conf = 0.8) ofrece reglas más interesantes desde el punto de vista analítico, al presentar mayor confianza y lift sin perder coherencia interpretativa.


```{r}
#Revisar items más frecuentes

itemFrequencyPlot(movies_trans, topN = 15)
```

##Conclusión final
El análisis de frecuencia de ítems mostró que el idioma inglés y la producción en Estados Unidos presentaban frecuencias extremadamente altas, generando reglas triviales y poco informativas. Por esta razón, se decidió eliminar dichas variables y volver a ejecutar el algoritmo A priori.

Tras esta depuración, el número de reglas se redujo significativamente (de 809 a 44 reglas), pero la calidad de las asociaciones aumentó considerablemente. El lift mínimo se incrementó a 2.39 y el lift promedio alcanzó aproximadamente 2.55, lo que indica asociaciones fuertes y consistentes.

Las reglas refinadas muestran que películas con presupuesto medio o alto, elevada popularidad, buena calificación promedio y un elenco amplio presentan entre 90% y 97% de probabilidad de generar ingresos altos. El lift cercano a 3 indica que estas asociaciones ocurren casi tres veces más de lo esperado bajo independencia.

Estos resultados confirman que el desempeño financiero de una película está fuertemente relacionado con su inversión inicial, nivel de exposición pública y percepción de calidad.
