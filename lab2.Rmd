---
title: "Lab2"
author: "Daniela Ramírez, Adrián Gonzáles y José Ordoñez"
date: "2026-02-23"
output: pdf_document
---

```{r librerias}
library(tidyverse)
library(lubridate)
library(cluster)
library(factoextra)
library(hopkins)
library(NbClust)
library(psych)
library(FactoMineR)
library(fpc)
library(factoextra)
library(corrplot)
library(PCAmixdata)
library(paran)
```


```{r datos}
movies <- read.csv("movies_2026.csv", stringsAsFactors = F)

str(movies)
```

```{r}
#Preprocesamiento de datos

movies_clust <- movies %>%
  dplyr::select(-id,
         -originalTitle,
         -title,
         -homePage,
         -director,
         -actors,
         -actorsCharacter,
         -productionCompany,
         -productionCompanyCountry,
         -productionCountry,
         -releaseDate)

# Eliminar NA
movies_clust <- movies_clust %>%
  drop_na()

# Seleccionar variables numéricas
movies_num <- movies_clust %>%
  dplyr::select(where(is.numeric))

# Escalar datos
movies_scaled <- scale(movies_num)
```

```{r}

set.seed(123)

# Tomar muestra de 1000 observaciones
sample_index <- sample(1:nrow(movies_scaled), 1000)

movies_sample <- movies_scaled[sample_index, ]

# Hopkins
hopkins_stat <- hopkins::hopkins(
  X = movies_sample,
  m = floor(0.1 * nrow(movies_sample))
)

hopkins_stat
```
El estadístico de Hopkins obtuvo un valor de 0.999999999997353.

Un valor cercano a 1 indica fuerte tendencia al agrupamiento, mientras que valores cercanos a 0.5 indican distribución aleatoria.

Dado que el valor obtenido es mayor a 0.9, existe evidencia de que los datos presentan estructura de agrupamiento y por lo tanto es adecuado aplicar algoritmos de clustering.


```{r} 
# VAT con muestra
dist_matrix_sample <- dist(movies_sample)

image(as.matrix(dist_matrix_sample),
      main = "VAT - Visual Assessment (Muestra)")

fviz_dist(dist_matrix_sample,
          show_labels = FALSE) +
  ggtitle("Visual Assessment of Cluster Tendency (Muestra)")
```
La evaluación visual de la matriz de distancias muestra variaciones en la intensidad del color, lo cual sugiere cierta estructura en los datos. No se observan bloques completamente definidos, lo que indica que los grupos no están perfectamente separados, pero sí existe tendencia al agrupamiento.
Este resultado es consistente con el estadístico de Hopkins obtenido previamente, el cual confirmó la presencia de estructura no aleatoria en los datos.


```{r}
#Codo

fviz_nbclust(movies_scaled, kmeans, method = "wss") +
  ggtitle("Método del Codo")

# Ajustar según gráfica
k_opt <- 3
```
En la gráfica del método del codo se observa un punto de inflexión claro en k = 3, a partir del cual la reducción en la suma de cuadrados intra-cluster comienza a disminuir de forma más gradual.
Por esta razón se selecciona k = 3 como número óptimo de clusters, ya que representa un equilibrio adecuado entre reducción de variabilidad interna y simplicidad del modelo.


```{r}
#k-means

set.seed(123)

kmeans_model <- kmeans(
  movies_scaled,
  centers = k_opt,
  nstart = 25
)

movies_clust$kmeans_cluster <- kmeans_model$cluster
```

```{r}
#Clustering jerárquico

dist_matrix <- dist(movies_scaled)

hc_model <- hclust(dist_matrix, method = "ward.D2")

plot(hc_model, labels = FALSE)

hc_clusters <- cutree(hc_model, k = k_opt)

movies_clust$hc_cluster <- hc_clusters
```

```{r}
#Silueta

# K-means
sil_kmeans <- silhouette(kmeans_model$cluster, dist_matrix)

fviz_silhouette(sil_kmeans)

mean(sil_kmeans[, 3])


# Jerárquico
sil_hc <- silhouette(hc_clusters, dist_matrix)

fviz_silhouette(sil_hc)

mean(sil_hc[, 3])
```
El promedio del índice de silueta para K-means fue 0.357, mientras que para el clustering jerárquico fue 0.330.

Aunque ambos métodos presentan una separación moderada entre grupos, K-means muestra un mejor desempeño global según el promedio de silueta.

Por esta razón se selecciona K-means como el método definitivo para la interpretación de los clusters.

```{r}
#Interpretación de datos
movies_clust %>%
  group_by(kmeans_cluster) %>%
  summarise(across(where(is.numeric), mean))

# Géneros
movies_clust %>%
  group_by(kmeans_cluster, genres) %>%
  summarise(n = n()) %>%
  arrange(kmeans_cluster, desc(n))

# Idioma original
movies_clust %>%
  group_by(kmeans_cluster, originalLanguage) %>%
  summarise(n = n()) %>%
  arrange(kmeans_cluster, desc(n))
```

## Interpretación de los Clusters (K-means)

Cluster 1:
Se caracteriza por películas de alto presupuesto (≈88 millones) y altos ingresos (≈327 millones), con elevada popularidad y duración promedio de 121 minutos. Predominan producciones en idioma inglés y géneros comerciales como comedia, drama y acción/aventura. Este grupo representa películas comerciales de alto rendimiento o “blockbusters” orientadas al mercado internacional.

Cluster 2:
Incluye películas de presupuesto medio (≈9 millones) y recaudación moderada (≈20 millones). Presentan menor popularidad en comparación con el Cluster 1 y mayor diversidad de idiomas, incluyendo producciones en inglés y japonés. Este grupo puede interpretarse como cine independiente o producciones regionales con alcance moderado.

Cluster 3:
Está compuesto por producciones de muy bajo presupuesto y escasa recaudación, con baja duración promedio y mínima popularidad. Este segmento podría representar cortometrajes o producciones de bajo impacto comercial.



```{r datos-pca}
datos_pca <- movies[, c(
  "budget",
  "revenue",
  "runtime",
  "popularity",
  "voteAvg",
  "voteCount",
  "genresAmount",
  "productionCoAmount",
  "productionCountriesAmount",
  "actorsAmount",
  "castWomenAmount",
  "castMenAmount"
)]
```

## Inclusión de variables categóricas en el PCA

Las variables categóricas como género, idioma original o país de producción podrían transformarse mediante técnicas como codificación one-hot (dummies) para ser incluidas en el análisis.

Sin embargo, este tipo de transformación incrementaría considerablemente la dimensionalidad del conjunto de datos y podría introducir alta dispersión y ruido, afectando la estabilidad de los componentes principales.

Dado que el objetivo del PCA es reducir dimensionalidad y sintetizar información relevante, se decidió utilizar únicamente variables numéricas, ya que estas representan directamente magnitudes financieras, de popularidad y estructura de producción.

Por lo tanto, no se consideró conveniente incluir variables categóricas transformadas en este análisis.

```{r aplicar-pca}
rcor<-cor(datos_pca, use = "complete.obs")
det(rcor)

KMO(as.matrix(datos_pca))

```
Al obtener la determinante de la matriz de correlación, nos indica que las variables si están relacionadas entre si.

Utilizamos KMO para determinar si se puede utilizar análisis factorial para las combinaciones lineales de las variables.
Obtuvimos 0.76 como indice, esto se encuentra entre 0.7 y 0.8, lo cual nos indica que es una adecuación muestral aceptable.

```{r matriz-correlación}
matriz <- cor(datos_pca[,-1],use = "pairwise.complete.obs")
corrplot(matriz)
```
La matriz de correlación muestra múltiples correlaciones positivas moderadas y fuertes entre variables como revenue, voteCount y voteAvg, así como entre las variables relacionadas con el reparto y la producción. Esto indica redundancia de información y presencia de multicolinealidad, lo cual respalda la aplicación del Análisis de Componentes Principales para sintetizar la información en un menor número de componentes.

# Prueba de Esfericidad de Bartlett

``` {r}
cortest.bartlett(matriz, n = nrow(datos_pca))
```

La prueba de Bartlett arrojó un estadístico χ² = 50302.23 con 55 grados de libertad y un p-value < 0.001.
Dado que el valor p es menor a 0.05, se rechaza la hipótesis nula de que la matriz de correlación sea identidad.

Esto indica que existe correlación significativa entre las variables y, por lo tanto, es apropiado aplicar el Análisis de Componentes Principales.

# Índice KMO

``` {r}
KMO(matriz)
```
El índice KMO global fue 0.70, lo cual indica una adecuación aceptable del modelo factorial.

Aunque algunas variables presentan valores individuales bajos (principalmente las relacionadas con el elenco), el valor global sugiere que el conjunto de datos es adecuado para aplicar PCA.

# Ajustes adicionales
```{r}
# Convertir a numérico
datos_pca[] <- lapply(datos_pca, function(x) as.numeric(as.character(x)))

# Eliminar NA
datos_pca <- na.omit(datos_pca)

# Escalar datos
datos_scaled <- scale(datos_pca)

# Crear objeto PCA
pca <- prcomp(datos_scaled, center = TRUE, scale. = TRUE)
```


```{r}
summary(pca)
fviz_eig(pca, addlabels = TRUE)
round(pca$rotation, 3)
```

El análisis muestra que:

La primera componente explica 38.23% de la varianza.

Las primeras cuatro componentes explican aproximadamente 71% de la variabilidad total.

Por lo tanto, se seleccionan 4 componentes principales, ya que permiten reducir la dimensionalidad manteniendo la mayor parte de la información del conjunto de datos.

Las cargas factoriales indican que:

### Componente Principal 1 (PC1)

PC1 presenta cargas altas y positivas en variables como budget, revenue, voteCount y actorsAmount.

Esto indica que esta componente representa una dimensión asociada al impacto comercial y escala de producción.

### Componente Principal 2 (PC2)

PC2 muestra asociación con variables como productionCountriesAmount y productionCoAmount, lo que sugiere una dimensión relacionada con la complejidad e internacionalización de la producción.

Esta componente podría interpretarse como una medida del grado de colaboración internacional en la película.

### Componente Principal 3 (PC3)

PC3 se relaciona principalmente con variables del elenco (actorsAmount, castWomenAmount, castMenAmount), representando la estructura del reparto y composición del cast.

Esta dimensión permite diferenciar producciones según tamaño y composición del elenco.

### Componente Principal 4 (PC4)

PC4 está fuertemente influenciada por la variable popularity, representando una dimensión más asociada a percepción pública y tendencia mediática que a magnitudes financieras directas.

PCA es una técnica adecuada para sintetizar la información del dataset.

